{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a25e7f4a-cc4d-4c32-b988-52350b6950d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from main.VisionTransformer_Trainer import VisionTransformerTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c49863b4-afde-4e04-a092-6e3744ce54fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = Namespace(\n",
    "    use_gpu=torch.cuda.is_available(),  # Automatically detect if a GPU is available\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    gpu=0,  # GPU index to use (set to 0 if only one GPU is available)\n",
    "    use_multi_gpu=False,  # Set to True if you want to use multiple GPUs\n",
    "    device_ids=[0],  # List of GPU device IDs (if using multiple GPUs)\n",
    "    num_models=1,  # Number of models to initialize\n",
    "    img_size = 28,\n",
    "    patch_size=4,  # Patch size for the Vision Transformer\n",
    "    num_classes=10,  # Number of output classes (10 for MNIST)\n",
    "    embed_dim=16,  # Embedding dimension for the Vision Transformer\n",
    "    num_heads=4,  # Number of attention heads\n",
    "    depth=1,  # Number of Transformer blocks\n",
    "    dropout=0.1,  # Dropout rate\n",
    "    path = 'C:/My files/Notebooks/testing_notebook',\n",
    "    root_path = 'C:/My files/Notebooks/testing_notebook',\n",
    "    checkpoints = 'C:/My files/Notebooks/testing_notebook/checkpoints',\n",
    "    dataset = 'mnist',\n",
    "    data_path = 'C:/My files/NPM/ising_reg/mnist',\n",
    "    batch_size=1,\n",
    "    lradj = \"type1\",\n",
    "    val_split=0.005,  # Fraction of data for validation\n",
    "    test_split=0.99,  # Fraction of data for testing\n",
    "    patience = 100,\n",
    "    lambda_weight1 = 0.000001,\n",
    "    lambda_weight2 = 0.000001,\n",
    "    learning_rate = 0.001,\n",
    "    kl_pen = 0.000001,\n",
    "    train_epochs = 1, \n",
    "    ising_epochs = 1, \n",
    "    addtl_ft = 0,\n",
    "    ising_type = \"LM_saliency_scores\" # options are: \"diag_saliency_scores\", \"LM_saliency_scores\", \"no_saliency_scores\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "61c7ee0f-c2ff-4a13-bbb7-114ae89de92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using CPU\n"
     ]
    }
   ],
   "source": [
    "trainer = VisionTransformerTrainer(args) # instantiated class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "54bc69d7-edff-4c12-9a49-3746d60017f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformerWithBBB(\n",
       "  (patch_embedding): BBBLinear(in_features=48, out_features=16, bias=True)\n",
       "  (encoder): ModuleList(\n",
       "    (0): TransformerEncoderLayerWithBBB(\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=16, out_features=16, bias=True)\n",
       "      )\n",
       "      (norm1): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      (norm2): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): BBBLinear(in_features=16, out_features=64, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.1, inplace=False)\n",
       "        (3): BBBLinear(in_features=64, out_features=16, bias=True)\n",
       "        (4): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classification_head): Sequential(\n",
       "    (0): BBBLinear(in_features=16, out_features=8, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.1, inplace=False)\n",
       "    (3): BBBLinear(in_features=8, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_model = trainer.models[0] # checking model instantiated properly\n",
    "active_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89443b80-c4b4-46cc-85c1-c077a191d718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training length: 597\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 1 | loss for each model: [2.343585430383682]\n",
      "\tspeed: 0.0142s/iter\n",
      "\titers: 200, epoch: 1 | loss for each model: [2.341725239753723]\n",
      "\tspeed: 0.0140s/iter\n",
      "\titers: 300, epoch: 1 | loss for each model: [2.3327513535817466]\n",
      "\tspeed: 0.0149s/iter\n",
      "\titers: 400, epoch: 1 | loss for each model: [2.328413217961788]\n",
      "\tspeed: 0.0160s/iter\n",
      "\titers: 500, epoch: 1 | loss for each model: [2.3248028888702392]\n",
      "\tspeed: 0.0150s/iter\n",
      "Epoch: 1 cost time: 8.813490629196167\n"
     ]
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7e3897d-92ec-4a95-8a79-a91362dd6021",
   "metadata": {},
   "outputs": [],
   "source": [
    "trainer.evaluate()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

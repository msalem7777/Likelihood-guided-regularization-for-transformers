{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0e5427cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.chdir('C:/My files/NPM/repo/Likelihood-guided-regularization-for-transformers')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a25e7f4a-cc4d-4c32-b988-52350b6950d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "import torch\n",
    "from main.pVisionTransformer_Trainer import pVisionTransformerTrainer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb1706d4-b6b6-4297-a350-174cfee45d08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-10-python.tar.gz to ./cifar10\\cifar-10-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 170M/170M [00:01<00:00, 105MB/s]  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar10\\cifar-10-python.tar.gz to ./cifar10\n",
      "Downloading https://www.cs.toronto.edu/~kriz/cifar-100-python.tar.gz to ./cifar100\\cifar-100-python.tar.gz\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|â–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆâ–ˆ| 169M/169M [00:06<00:00, 26.9MB/s] \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting ./cifar100\\cifar-100-python.tar.gz to ./cifar100\n",
      "CIFAR-10 and CIFAR-100 datasets downloaded.\n"
     ]
    }
   ],
   "source": [
    "# %run data_loader/mnist_fmnist_downloader.py\n",
    "%run data_loader/cifar_downloader.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "c49863b4-afde-4e04-a092-6e3744ce54fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "from argparse import Namespace\n",
    "\n",
    "args = Namespace(\n",
    "    use_gpu=torch.cuda.is_available(),  # Automatically detect if a GPU is available\n",
    "    device=torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\"),\n",
    "    gpu=0,  # GPU index to use (set to 0 if only one GPU is available)\n",
    "    use_multi_gpu=False,  # Set to True if you want to use multiple GPUs\n",
    "    device_ids=[0],  # List of GPU device IDs (if using multiple GPUs)\n",
    "    num_models=1,  # Number of models to initialize\n",
    "    img_size = 28,\n",
    "    patch_size=7,  # Patch size for the Vision Transformer\n",
    "    num_classes=10,  # Number of output classes (10 for MNIST)\n",
    "    embed_dim=64,  # Embedding dimension for the Vision Transformer\n",
    "    num_heads=32,  # Number of attention heads\n",
    "    depth=2,  # Number of Transformer blocks\n",
    "    dropout=0.0,  # Dropout rate\n",
    "    path = '.',\n",
    "    root_path = '.',\n",
    "    checkpoints = './checkpoints',\n",
    "    dataset = 'mnist',\n",
    "    data_path = './mnist',\n",
    "    batch_size=20,\n",
    "    lradj = \"type2\",\n",
    "    val_split=0.80,  # Fraction of data for validation\n",
    "    test_split=0.10,  # Fraction of data for testing\n",
    "    patience = 100,\n",
    "    lambda_weight1 = 0.000001,\n",
    "    lambda_weight2 = 0.000001,\n",
    "    learning_rate = 0.001,\n",
    "    kl_pen = 0.000001,\n",
    "    train_epochs = 25, \n",
    "    ising_epochs = 5, \n",
    "    addtl_ft = 25,\n",
    "    ising_type = \"no_saliency_scores\", # options are: \"diag_saliency_scores\", \"LM_saliency_scores\", \"no_saliency_scores\",\n",
    "    num_workers = 0, # number of workers for data loading\n",
    "    ising_batch = True\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "61c7ee0f-c2ff-4a13-bbb7-114ae89de92b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using GPU: cuda:0\n"
     ]
    }
   ],
   "source": [
    "trainer = pVisionTransformerTrainer(args) # instantiated class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "id": "54bc69d7-edff-4c12-9a49-3746d60017f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformerWithBBB(\n",
       "  (patch_embedding): BBBLinear(in_features=147, out_features=64, bias=True)\n",
       "  (encoder): ModuleList(\n",
       "    (0-1): 2 x TransformerEncoderLayerWithBBB(\n",
       "      (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (self_attn): MultiheadAttention(\n",
       "        (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "      )\n",
       "      (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "      (mlp): Sequential(\n",
       "        (0): BBBLinear(in_features=64, out_features=256, bias=True)\n",
       "        (1): GELU(approximate='none')\n",
       "        (2): Dropout(p=0.0, inplace=False)\n",
       "        (3): BBBLinear(in_features=256, out_features=64, bias=True)\n",
       "        (4): Dropout(p=0.0, inplace=False)\n",
       "      )\n",
       "    )\n",
       "  )\n",
       "  (classification_head): Sequential(\n",
       "    (0): BBBLinear(in_features=64, out_features=32, bias=True)\n",
       "    (1): ReLU()\n",
       "    (2): Dropout(p=0.0, inplace=False)\n",
       "    (3): BBBLinear(in_features=32, out_features=10, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "active_model = trainer.models[0] # checking model instantiated properly\n",
    "active_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "89443b80-c4b4-46cc-85c1-c077a191d718",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training length: 6000\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 1 | loss for each model: [2.206815142631531]\n",
      "\tspeed: 0.0167s/iter\n",
      "\titers: 200, epoch: 1 | loss for each model: [1.8790253376960755]\n",
      "\tspeed: 0.0139s/iter\n",
      "\titers: 300, epoch: 1 | loss for each model: [1.6655901441971461]\n",
      "\tspeed: 0.0141s/iter\n",
      "Epoch: 1 cost time: 4.46903920173645\n",
      "Epoch: 1, Train Loss: [1.6655901441971461], Vali Loss: [1.1869396782935935], Test Loss: [1.1745347181955974]\n",
      "ðŸ” Phase changed from None â†’ pilot\n",
      "Model 0: Validation loss decreased (inf --> 1.186940).  Saving model ...\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 2 | loss for each model: [0.9946298667788506]\n",
      "\tspeed: 0.0154s/iter\n",
      "\titers: 200, epoch: 2 | loss for each model: [0.94603994846344]\n",
      "\tspeed: 0.0140s/iter\n",
      "\titers: 300, epoch: 2 | loss for each model: [0.9005318214495976]\n",
      "\tspeed: 0.0143s/iter\n",
      "Epoch: 2 cost time: 4.36864709854126\n",
      "Epoch: 2, Train Loss: [0.9005318214495976], Vali Loss: [0.7778435273373381], Test Loss: [0.7631906569004059]\n",
      "Model 0: Validation loss decreased (1.186940 --> 0.777844).  Saving model ...\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 3 | loss for each model: [0.6654414349794388]\n",
      "\tspeed: 0.0165s/iter\n",
      "\titers: 200, epoch: 3 | loss for each model: [0.6640571773052215]\n",
      "\tspeed: 0.0181s/iter\n",
      "\titers: 300, epoch: 3 | loss for each model: [0.6530226187904676]\n",
      "\tspeed: 0.0193s/iter\n",
      "Epoch: 3 cost time: 5.398685693740845\n",
      "Epoch: 3, Train Loss: [0.6530226187904676], Vali Loss: [0.6131291998193619], Test Loss: [0.6147618293762207]\n",
      "Model 0: Validation loss decreased (0.777844 --> 0.613129).  Saving model ...\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 4 | loss for each model: [0.5009565079212188]\n",
      "\tspeed: 0.0158s/iter\n",
      "\titers: 200, epoch: 4 | loss for each model: [0.5345314114540816]\n",
      "\tspeed: 0.0156s/iter\n",
      "\titers: 300, epoch: 4 | loss for each model: [0.517198279996713]\n",
      "\tspeed: 0.0154s/iter\n",
      "Epoch: 4 cost time: 4.68282675743103\n",
      "Epoch: 4, Train Loss: [0.517198279996713], Vali Loss: [0.6075663224179694], Test Loss: [0.5798001686731974]\n",
      "Model 0: Validation loss decreased (0.613129 --> 0.607566).  Saving model ...\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 5 | loss for each model: [0.4357638826221228]\n",
      "\tspeed: 0.0186s/iter\n",
      "\titers: 200, epoch: 5 | loss for each model: [0.44760184954851867]\n",
      "\tspeed: 0.0225s/iter\n",
      "\titers: 300, epoch: 5 | loss for each model: [0.43792076530555885]\n",
      "\tspeed: 0.0203s/iter\n",
      "Epoch: 5 cost time: 6.137218952178955\n",
      "Epoch: 5, Train Loss: [0.43792076530555885], Vali Loss: [0.5174558308530361], Test Loss: [0.5136688699324926]\n",
      "Model 0: Validation loss decreased (0.607566 --> 0.517456).  Saving model ...\n",
      "Updating learning rate to 0.0005\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 6 | loss for each model: [0.2947405843436718]\n",
      "\tspeed: 0.0164s/iter\n",
      "\titers: 200, epoch: 6 | loss for each model: [0.30600806638598443]\n",
      "\tspeed: 0.0167s/iter\n",
      "\titers: 300, epoch: 6 | loss for each model: [0.30140584415445726]\n",
      "\tspeed: 0.0161s/iter\n",
      "Epoch: 6 cost time: 4.922267436981201\n",
      "Epoch: 6, Train Loss: [0.30140584415445726], Vali Loss: [0.4732923742304457], Test Loss: [0.4892002195119858]\n",
      "Model 0: Validation loss decreased (0.517456 --> 0.473292).  Saving model ...\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 7 | loss for each model: [0.24976824147626758]\n",
      "\tspeed: 0.0151s/iter\n",
      "\titers: 200, epoch: 7 | loss for each model: [0.24758193667046727]\n",
      "\tspeed: 0.0138s/iter\n",
      "\titers: 300, epoch: 7 | loss for each model: [0.24778478117659689]\n",
      "\tspeed: 0.0141s/iter\n",
      "Epoch: 7 cost time: 4.30042290687561\n",
      "Epoch: 7, Train Loss: [0.24778478117659689], Vali Loss: [0.42629976665720026], Test Loss: [0.44717103739579517]\n",
      "Model 0: Validation loss decreased (0.473292 --> 0.426300).  Saving model ...\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 8 | loss for each model: [0.21299808007664978]\n",
      "\tspeed: 0.0139s/iter\n",
      "\titers: 200, epoch: 8 | loss for each model: [0.2124233917752281]\n",
      "\tspeed: 0.0136s/iter\n",
      "\titers: 300, epoch: 8 | loss for each model: [0.2186485125279675]\n",
      "\tspeed: 0.0136s/iter\n",
      "Epoch: 8 cost time: 4.108557939529419\n",
      "Epoch: 8, Train Loss: [0.2186485125279675], Vali Loss: [0.4247530698776245], Test Loss: [0.42362867792447406]\n",
      "Model 0: Validation loss decreased (0.426300 --> 0.424753).  Saving model ...\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 9 | loss for each model: [0.16801805718336255]\n",
      "\tspeed: 0.0150s/iter\n",
      "\titers: 200, epoch: 9 | loss for each model: [0.1803860200732015]\n",
      "\tspeed: 0.0161s/iter\n",
      "\titers: 300, epoch: 9 | loss for each model: [0.19182566509426882]\n",
      "\tspeed: 0.0137s/iter\n",
      "Epoch: 9 cost time: 4.475980758666992\n",
      "Epoch: 9, Train Loss: [0.19182566509426882], Vali Loss: [0.41421486532434504], Test Loss: [0.4204455514748891]\n",
      "Model 0: Validation loss decreased (0.424753 --> 0.414215).  Saving model ...\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 10 | loss for each model: [0.17116912455298006]\n",
      "\tspeed: 0.0139s/iter\n",
      "\titers: 200, epoch: 10 | loss for each model: [0.16766685091424732]\n",
      "\tspeed: 0.0163s/iter\n",
      "\titers: 300, epoch: 10 | loss for each model: [0.17141105413126448]\n",
      "\tspeed: 0.0157s/iter\n",
      "Epoch: 10 cost time: 4.584479808807373\n",
      "Epoch: 10, Train Loss: [0.17141105413126448], Vali Loss: [0.43183886370760327], Test Loss: [0.42746034761269885]\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Updating learning rate to 0.00025\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 11 | loss for each model: [0.11165469677187502]\n",
      "\tspeed: 0.0145s/iter\n",
      "\titers: 200, epoch: 11 | loss for each model: [0.10786005300935358]\n",
      "\tspeed: 0.0136s/iter\n",
      "\titers: 300, epoch: 11 | loss for each model: [0.10439624358201399]\n",
      "\tspeed: 0.0136s/iter\n",
      "Epoch: 11 cost time: 4.179983139038086\n",
      "Epoch: 11, Train Loss: [0.10439624358201399], Vali Loss: [0.41724296960424867], Test Loss: [0.4191245635350545]\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 12 | loss for each model: [0.0906707086134702]\n",
      "\tspeed: 0.0146s/iter\n",
      "\titers: 200, epoch: 12 | loss for each model: [0.08548140130471438]\n",
      "\tspeed: 0.0151s/iter\n",
      "\titers: 300, epoch: 12 | loss for each model: [0.08663555468510216]\n",
      "\tspeed: 0.0149s/iter\n",
      "Epoch: 12 cost time: 4.459425687789917\n",
      "Epoch: 12, Train Loss: [0.08663555468510216], Vali Loss: [0.4454970207620174], Test Loss: [0.4512718419233958]\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 13 | loss for each model: [0.08642500441055745]\n",
      "\tspeed: 0.0151s/iter\n",
      "\titers: 200, epoch: 13 | loss for each model: [0.07434893871541134]\n",
      "\tspeed: 0.0146s/iter\n",
      "\titers: 300, epoch: 13 | loss for each model: [0.07388682100766648]\n",
      "\tspeed: 0.0143s/iter\n",
      "Epoch: 13 cost time: 4.401852369308472\n",
      "Epoch: 13, Train Loss: [0.07388682100766648], Vali Loss: [0.4603594909323023], Test Loss: [0.46791625022888184]\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 14 | loss for each model: [0.06777111271163448]\n",
      "\tspeed: 0.0140s/iter\n",
      "\titers: 200, epoch: 14 | loss for each model: [0.06547052049601916]\n",
      "\tspeed: 0.0137s/iter\n",
      "\titers: 300, epoch: 14 | loss for each model: [0.06697049662199182]\n",
      "\tspeed: 0.0138s/iter\n",
      "Epoch: 14 cost time: 4.153748989105225\n",
      "Epoch: 14, Train Loss: [0.06697049662199182], Vali Loss: [0.4860387450837074], Test Loss: [0.5033047248919805]\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 15 | loss for each model: [0.059349413636373353]\n",
      "\tspeed: 0.0147s/iter\n",
      "\titers: 200, epoch: 15 | loss for each model: [0.05618868025718257]\n",
      "\tspeed: 0.0138s/iter\n",
      "\titers: 300, epoch: 15 | loss for each model: [0.06107472361453498]\n",
      "\tspeed: 0.0142s/iter\n",
      "Epoch: 15 cost time: 4.272048234939575\n",
      "Epoch: 15, Train Loss: [0.06107472361453498], Vali Loss: [0.5019190482636715], Test Loss: [0.513257622718811]\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Updating learning rate to 0.000125\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 16 | loss for each model: [0.05130424445203971]\n",
      "\tspeed: 0.0179s/iter\n",
      "\titers: 200, epoch: 16 | loss for each model: [0.04247310012200614]\n",
      "\tspeed: 0.0186s/iter\n",
      "\titers: 300, epoch: 16 | loss for each model: [0.042210858155352374]\n",
      "\tspeed: 0.0233s/iter\n",
      "Epoch: 16 cost time: 5.976740598678589\n",
      "Epoch: 16, Train Loss: [0.042210858155352374], Vali Loss: [0.49049038646068976], Test Loss: [0.48548022905985516]\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 17 | loss for each model: [0.027530189281969798]\n",
      "\tspeed: 0.0138s/iter\n",
      "\titers: 200, epoch: 17 | loss for each model: [0.03687598297998193]\n",
      "\tspeed: 0.0145s/iter\n",
      "\titers: 300, epoch: 17 | loss for each model: [0.03343588178589319]\n",
      "\tspeed: 0.0204s/iter\n",
      "Epoch: 17 cost time: 4.875052452087402\n",
      "Epoch: 17, Train Loss: [0.03343588178589319], Vali Loss: [0.4952868514872612], Test Loss: [0.5156981647014618]\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 18 | loss for each model: [0.024617786054732277]\n",
      "\tspeed: 0.0204s/iter\n",
      "\titers: 200, epoch: 18 | loss for each model: [0.024056169300165492]\n",
      "\tspeed: 0.0188s/iter\n",
      "\titers: 300, epoch: 18 | loss for each model: [0.02692496332892915]\n",
      "\tspeed: 0.0221s/iter\n",
      "Epoch: 18 cost time: 6.129817724227905\n",
      "Epoch: 18, Train Loss: [0.02692496332892915], Vali Loss: [0.5117299252368034], Test Loss: [0.5323688387870789]\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 19 | loss for each model: [0.028360056445235385]\n",
      "\tspeed: 0.0204s/iter\n",
      "\titers: 200, epoch: 19 | loss for each model: [0.027005334852437956]\n",
      "\tspeed: 0.0220s/iter\n",
      "\titers: 300, epoch: 19 | loss for each model: [0.028868306803827484]\n",
      "\tspeed: 0.0198s/iter\n",
      "Epoch: 19 cost time: 6.218270540237427\n",
      "Epoch: 19, Train Loss: [0.028868306803827484], Vali Loss: [0.5403797144585467], Test Loss: [0.5434507429599762]\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 20 | loss for each model: [0.021551236216328106]\n",
      "\tspeed: 0.0193s/iter\n",
      "\titers: 200, epoch: 20 | loss for each model: [0.020134310598332376]\n",
      "\tspeed: 0.0197s/iter\n",
      "\titers: 300, epoch: 20 | loss for each model: [0.022964205993218155]\n",
      "\tspeed: 0.0183s/iter\n",
      "Epoch: 20 cost time: 5.731343030929565\n",
      "Epoch: 20, Train Loss: [0.022964205993218155], Vali Loss: [0.5347635403592536], Test Loss: [0.5447604060173035]\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Updating learning rate to 6.25e-05\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 21 | loss for each model: [0.021237110800284426]\n",
      "\tspeed: 0.0178s/iter\n",
      "\titers: 200, epoch: 21 | loss for each model: [0.019257590137335683]\n",
      "\tspeed: 0.0187s/iter\n",
      "\titers: 300, epoch: 21 | loss for each model: [0.019343226132711302]\n",
      "\tspeed: 0.0186s/iter\n",
      "Epoch: 21 cost time: 5.516157627105713\n",
      "Epoch: 21, Train Loss: [0.019343226132711302], Vali Loss: [0.5322635776184975], Test Loss: [0.5323795229196548]\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 22 | loss for each model: [0.014411476074310486]\n",
      "\tspeed: 0.0192s/iter\n",
      "\titers: 200, epoch: 22 | loss for each model: [0.01442520008487918]\n",
      "\tspeed: 0.0187s/iter\n",
      "\titers: 300, epoch: 22 | loss for each model: [0.017216671581263655]\n",
      "\tspeed: 0.0195s/iter\n",
      "Epoch: 22 cost time: 5.74203085899353\n",
      "Epoch: 22, Train Loss: [0.017216671581263655], Vali Loss: [0.5480854492238227], Test Loss: [0.5633051594098409]\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 23 | loss for each model: [0.019333050868044665]\n",
      "\tspeed: 0.0196s/iter\n",
      "\titers: 200, epoch: 23 | loss for each model: [0.015323547446223528]\n",
      "\tspeed: 0.0180s/iter\n",
      "\titers: 300, epoch: 23 | loss for each model: [0.0166025626493744]\n",
      "\tspeed: 0.0180s/iter\n",
      "Epoch: 23 cost time: 5.565919876098633\n",
      "Epoch: 23, Train Loss: [0.0166025626493744], Vali Loss: [0.5544693330500988], Test Loss: [0.5698171456654867]\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 24 | loss for each model: [0.016748388351406903]\n",
      "\tspeed: 0.0192s/iter\n",
      "\titers: 200, epoch: 24 | loss for each model: [0.014449629616719903]\n",
      "\tspeed: 0.0175s/iter\n",
      "\titers: 300, epoch: 24 | loss for each model: [0.014618208239844534]\n",
      "\tspeed: 0.0174s/iter\n",
      "Epoch: 24 cost time: 5.410195350646973\n",
      "Epoch: 24, Train Loss: [0.014618208239844534], Vali Loss: [0.5622804913114994], Test Loss: [0.5811613202095032]\n",
      "EarlyStopping counter: 15 out of 100\n",
      "Current phase set to: pilot\n",
      "\titers: 100, epoch: 25 | loss for each model: [0.5428986139344575]\n",
      "\tspeed: 0.0156s/iter\n",
      "\titers: 200, epoch: 25 | loss for each model: [0.6032087291062243]\n",
      "\tspeed: 0.0139s/iter\n",
      "\titers: 300, epoch: 25 | loss for each model: [0.4942181865611063]\n",
      "\tspeed: 0.0137s/iter\n",
      "\titers: 400, epoch: 25 | loss for each model: [0.5387200860228131]\n",
      "\tspeed: 0.0140s/iter\n",
      "\titers: 500, epoch: 25 | loss for each model: [0.512827666197827]\n",
      "\tspeed: 0.0150s/iter\n",
      "\titers: 600, epoch: 25 | loss for each model: [0.5192044183201784]\n",
      "\tspeed: 0.0154s/iter\n",
      "\titers: 700, epoch: 25 | loss for each model: [0.4928712416661629]\n",
      "\tspeed: 0.0150s/iter\n",
      "\titers: 800, epoch: 25 | loss for each model: [0.470861669367056]\n",
      "\tspeed: 0.0141s/iter\n",
      "\titers: 900, epoch: 25 | loss for each model: [0.47704551045510635]\n",
      "\tspeed: 0.0154s/iter\n",
      "\titers: 1000, epoch: 25 | loss for each model: [0.47103003149416395]\n",
      "\tspeed: 0.0144s/iter\n",
      "\titers: 1100, epoch: 25 | loss for each model: [0.48617078301449335]\n",
      "\tspeed: 0.0158s/iter\n",
      "\titers: 1200, epoch: 25 | loss for each model: [0.5063134004295976]\n",
      "\tspeed: 0.0143s/iter\n",
      "\titers: 1300, epoch: 25 | loss for each model: [0.5319044074296648]\n",
      "\tspeed: 0.0136s/iter\n",
      "\titers: 1400, epoch: 25 | loss for each model: [0.5298582659451344]\n",
      "\tspeed: 0.0133s/iter\n",
      "\titers: 1500, epoch: 25 | loss for each model: [0.5296686503380884]\n",
      "\tspeed: 0.0133s/iter\n",
      "\titers: 1600, epoch: 25 | loss for each model: [0.5370379258571097]\n",
      "\tspeed: 0.0147s/iter\n",
      "\titers: 1700, epoch: 25 | loss for each model: [0.5318363939589834]\n",
      "\tspeed: 0.0140s/iter\n",
      "\titers: 1800, epoch: 25 | loss for each model: [0.5341393987809283]\n",
      "\tspeed: 0.0136s/iter\n",
      "\titers: 1900, epoch: 25 | loss for each model: [0.5313995098006584]\n",
      "\tspeed: 0.0134s/iter\n",
      "\titers: 2000, epoch: 25 | loss for each model: [0.5226334758369903]\n",
      "\tspeed: 0.0162s/iter\n",
      "\titers: 2100, epoch: 25 | loss for each model: [0.5247099603883699]\n",
      "\tspeed: 0.0136s/iter\n",
      "\titers: 2200, epoch: 25 | loss for each model: [0.5209231624313913]\n",
      "\tspeed: 0.0133s/iter\n",
      "\titers: 2300, epoch: 25 | loss for each model: [0.5189885620368618]\n",
      "\tspeed: 0.0135s/iter\n",
      "\titers: 2400, epoch: 25 | loss for each model: [0.5136832793477669]\n",
      "\tspeed: 0.0136s/iter\n",
      "\titers: 2500, epoch: 25 | loss for each model: [0.5081554024933598]\n",
      "\tspeed: 0.0132s/iter\n",
      "\titers: 2600, epoch: 25 | loss for each model: [0.4989780770544457]\n",
      "\tspeed: 0.0150s/iter\n",
      "\titers: 2700, epoch: 25 | loss for each model: [0.4881175629129034]\n",
      "\tspeed: 0.0170s/iter\n",
      "\titers: 2800, epoch: 25 | loss for each model: [0.4931823336769845]\n",
      "\tspeed: 0.0144s/iter\n",
      "\titers: 2900, epoch: 25 | loss for each model: [0.4904708330405059]\n",
      "\tspeed: 0.0142s/iter\n",
      "\titers: 3000, epoch: 25 | loss for each model: [0.5016928740559635]\n",
      "\tspeed: 0.0142s/iter\n",
      "\titers: 3100, epoch: 25 | loss for each model: [0.5014996857918802]\n",
      "\tspeed: 0.0135s/iter\n",
      "\titers: 3200, epoch: 25 | loss for each model: [0.4990911025725262]\n",
      "\tspeed: 0.0137s/iter\n",
      "\titers: 3300, epoch: 25 | loss for each model: [0.49477064493430534]\n",
      "\tspeed: 0.0134s/iter\n",
      "\titers: 3400, epoch: 25 | loss for each model: [0.49827228131449386]\n",
      "\tspeed: 0.0142s/iter\n",
      "\titers: 3500, epoch: 25 | loss for each model: [0.5027208051313591]\n",
      "\tspeed: 0.0132s/iter\n",
      "\titers: 3600, epoch: 25 | loss for each model: [0.4991199258308859]\n",
      "\tspeed: 0.0124s/iter\n",
      "\titers: 3700, epoch: 25 | loss for each model: [0.49729013356456375]\n",
      "\tspeed: 0.0161s/iter\n",
      "\titers: 3800, epoch: 25 | loss for each model: [0.49102885237370103]\n",
      "\tspeed: 0.0140s/iter\n",
      "\titers: 3900, epoch: 25 | loss for each model: [0.4952396851075797]\n",
      "\tspeed: 0.0179s/iter\n",
      "\titers: 4000, epoch: 25 | loss for each model: [0.49760172224460847]\n",
      "\tspeed: 0.0163s/iter\n",
      "\titers: 4100, epoch: 25 | loss for each model: [0.4957571160782942]\n",
      "\tspeed: 0.0157s/iter\n",
      "\titers: 4200, epoch: 25 | loss for each model: [0.49512689452964076]\n",
      "\tspeed: 0.0130s/iter\n",
      "\titers: 4300, epoch: 25 | loss for each model: [0.49073749533870625]\n",
      "\tspeed: 0.0144s/iter\n",
      "\titers: 4400, epoch: 25 | loss for each model: [0.48998922494100416]\n",
      "\tspeed: 0.0150s/iter\n",
      "\titers: 4500, epoch: 25 | loss for each model: [0.4849609038690762]\n",
      "\tspeed: 0.0186s/iter\n",
      "\titers: 4600, epoch: 25 | loss for each model: [0.4835330013616389]\n",
      "\tspeed: 0.0155s/iter\n",
      "\titers: 4700, epoch: 25 | loss for each model: [0.47972227342592055]\n",
      "\tspeed: 0.0170s/iter\n",
      "\titers: 4800, epoch: 25 | loss for each model: [0.47488513888535816]\n",
      "\tspeed: 0.0186s/iter\n",
      "\titers: 4900, epoch: 25 | loss for each model: [0.4718201831320603]\n",
      "\tspeed: 0.0145s/iter\n",
      "\titers: 5000, epoch: 25 | loss for each model: [0.46765074406472834]\n",
      "\tspeed: 0.0147s/iter\n",
      "\titers: 5100, epoch: 25 | loss for each model: [0.4694160794404667]\n",
      "\tspeed: 0.0176s/iter\n",
      "\titers: 5200, epoch: 25 | loss for each model: [0.4682619167760293]\n",
      "\tspeed: 0.0148s/iter\n",
      "\titers: 5300, epoch: 25 | loss for each model: [0.4701795112889484]\n",
      "\tspeed: 0.0139s/iter\n",
      "\titers: 5400, epoch: 25 | loss for each model: [0.4721186813299344]\n",
      "\tspeed: 0.0142s/iter\n",
      "\titers: 5500, epoch: 25 | loss for each model: [0.4681727596866205]\n",
      "\tspeed: 0.0142s/iter\n",
      "\titers: 5600, epoch: 25 | loss for each model: [0.4667231499265857]\n",
      "\tspeed: 0.0145s/iter\n",
      "\titers: 5700, epoch: 25 | loss for each model: [0.4685156222773624]\n",
      "\tspeed: 0.0143s/iter\n",
      "\titers: 5800, epoch: 25 | loss for each model: [0.4655686208139474]\n",
      "\tspeed: 0.0254s/iter\n",
      "\titers: 5900, epoch: 25 | loss for each model: [0.4646484224099659]\n",
      "\tspeed: 0.0174s/iter\n",
      "\titers: 6000, epoch: 25 | loss for each model: [0.46142352242311624]\n",
      "\tspeed: 0.0147s/iter\n",
      "Epoch: 25 cost time: 89.3741397857666\n",
      "Epoch: 25, Train Loss: [0.46142352242311624], Vali Loss: [0.36643471362742974], Test Loss: [0.34612982471783954]\n",
      "Model 0: Validation loss decreased (0.414215 --> 0.366435).  Saving model ...\n",
      "Updating learning rate to 3.125e-05\n",
      "Current phase set to: ising\n",
      "\titers: 100, epoch: 26 | loss for each model: [1.2072236987948417]\n",
      "\tspeed: 0.0200s/iter\n",
      "\titers: 200, epoch: 26 | loss for each model: [1.1971401542425155]\n",
      "\tspeed: 0.0203s/iter\n",
      "\titers: 300, epoch: 26 | loss for each model: [1.171881766617298]\n",
      "\tspeed: 0.0214s/iter\n",
      "\titers: 400, epoch: 26 | loss for each model: [1.1501875990256667]\n",
      "\tspeed: 0.0198s/iter\n",
      "\titers: 500, epoch: 26 | loss for each model: [1.1383484233319758]\n",
      "\tspeed: 0.0220s/iter\n",
      "\titers: 600, epoch: 26 | loss for each model: [1.1130157319704692]\n",
      "\tspeed: 0.0203s/iter\n",
      "\titers: 700, epoch: 26 | loss for each model: [1.090418598545449]\n",
      "\tspeed: 0.0208s/iter\n",
      "\titers: 800, epoch: 26 | loss for each model: [1.0653852195106446]\n",
      "\tspeed: 0.0212s/iter\n",
      "\titers: 900, epoch: 26 | loss for each model: [1.0417350683857998]\n",
      "\tspeed: 0.0204s/iter\n",
      "\titers: 1000, epoch: 26 | loss for each model: [1.0188838768824935]\n",
      "\tspeed: 0.0212s/iter\n",
      "\titers: 1100, epoch: 26 | loss for each model: [1.0017758038978686]\n",
      "\tspeed: 0.0210s/iter\n",
      "\titers: 1200, epoch: 26 | loss for each model: [0.9880712356977165]\n",
      "\tspeed: 0.0206s/iter\n",
      "\titers: 1300, epoch: 26 | loss for each model: [0.9830980577950295]\n",
      "\tspeed: 0.0204s/iter\n",
      "\titers: 1400, epoch: 26 | loss for each model: [0.9729822805151344]\n",
      "\tspeed: 0.0204s/iter\n",
      "\titers: 1500, epoch: 26 | loss for each model: [0.9571559717754523]\n",
      "\tspeed: 0.0233s/iter\n",
      "\titers: 1600, epoch: 26 | loss for each model: [0.944882837033365]\n",
      "\tspeed: 0.0191s/iter\n",
      "\titers: 1700, epoch: 26 | loss for each model: [0.9306075572069077]\n",
      "\tspeed: 0.0197s/iter\n",
      "\titers: 1800, epoch: 26 | loss for each model: [0.9186721261031926]\n",
      "\tspeed: 0.0224s/iter\n",
      "\titers: 1900, epoch: 26 | loss for each model: [0.9087195866731437]\n",
      "\tspeed: 0.0192s/iter\n",
      "\titers: 2000, epoch: 26 | loss for each model: [0.897469478821382]\n",
      "\tspeed: 0.0207s/iter\n",
      "\titers: 2100, epoch: 26 | loss for each model: [0.8840571808265079]\n",
      "\tspeed: 0.0204s/iter\n",
      "\titers: 2200, epoch: 26 | loss for each model: [0.872853624204343]\n",
      "\tspeed: 0.0223s/iter\n",
      "\titers: 2300, epoch: 26 | loss for each model: [0.8632244561078107]\n",
      "\tspeed: 0.0207s/iter\n",
      "\titers: 2400, epoch: 26 | loss for each model: [0.8580195992828036]\n",
      "\tspeed: 0.0188s/iter\n",
      "\titers: 2500, epoch: 26 | loss for each model: [0.8477946562066674]\n",
      "\tspeed: 0.0181s/iter\n",
      "\titers: 2600, epoch: 26 | loss for each model: [0.8404272478790238]\n",
      "\tspeed: 0.0192s/iter\n",
      "\titers: 2700, epoch: 26 | loss for each model: [0.8353597366082034]\n",
      "\tspeed: 0.0193s/iter\n",
      "\titers: 2800, epoch: 26 | loss for each model: [0.8244627429987303]\n",
      "\tspeed: 0.0208s/iter\n",
      "\titers: 2900, epoch: 26 | loss for each model: [0.8156633750044194]\n",
      "\tspeed: 0.0203s/iter\n",
      "\titers: 3000, epoch: 26 | loss for each model: [0.8035915788067505]\n",
      "\tspeed: 0.0278s/iter\n",
      "\titers: 3100, epoch: 26 | loss for each model: [0.7912139229100918]\n",
      "\tspeed: 0.0212s/iter\n",
      "\titers: 3200, epoch: 26 | loss for each model: [0.7854206214164151]\n",
      "\tspeed: 0.0213s/iter\n",
      "\titers: 3300, epoch: 26 | loss for each model: [0.7775623801333661]\n",
      "\tspeed: 0.0200s/iter\n",
      "\titers: 3400, epoch: 26 | loss for each model: [0.7723650912529625]\n",
      "\tspeed: 0.0192s/iter\n",
      "\titers: 3500, epoch: 26 | loss for each model: [0.7632121857026858]\n",
      "\tspeed: 0.0205s/iter\n",
      "\titers: 3600, epoch: 26 | loss for each model: [0.7572045572885933]\n",
      "\tspeed: 0.0200s/iter\n",
      "\titers: 3700, epoch: 26 | loss for each model: [0.7503513232379447]\n",
      "\tspeed: 0.0218s/iter\n",
      "\titers: 3800, epoch: 26 | loss for each model: [0.743438355862163]\n",
      "\tspeed: 0.0232s/iter\n",
      "\titers: 3900, epoch: 26 | loss for each model: [0.7353503190463361]\n",
      "\tspeed: 0.0198s/iter\n",
      "\titers: 4000, epoch: 26 | loss for each model: [0.7319486044049263]\n",
      "\tspeed: 0.0239s/iter\n",
      "\titers: 4100, epoch: 26 | loss for each model: [0.7287965613056155]\n",
      "\tspeed: 0.0214s/iter\n",
      "\titers: 4200, epoch: 26 | loss for each model: [0.723525510232319]\n",
      "\tspeed: 0.0205s/iter\n",
      "\titers: 4300, epoch: 26 | loss for each model: [0.7167232245856593]\n",
      "\tspeed: 0.0201s/iter\n",
      "\titers: 4400, epoch: 26 | loss for each model: [0.7100796087353956]\n",
      "\tspeed: 0.0207s/iter\n",
      "\titers: 4500, epoch: 26 | loss for each model: [0.7025016301623028]\n",
      "\tspeed: 0.0205s/iter\n",
      "\titers: 4600, epoch: 26 | loss for each model: [0.6988180172302679]\n",
      "\tspeed: 0.0211s/iter\n",
      "\titers: 4700, epoch: 26 | loss for each model: [0.6931759234588157]\n",
      "\tspeed: 0.0193s/iter\n",
      "\titers: 4800, epoch: 26 | loss for each model: [0.6866831313829365]\n",
      "\tspeed: 0.0206s/iter\n",
      "\titers: 4900, epoch: 26 | loss for each model: [0.6803303584164693]\n",
      "\tspeed: 0.0203s/iter\n",
      "\titers: 5000, epoch: 26 | loss for each model: [0.6747690304656513]\n",
      "\tspeed: 0.0210s/iter\n",
      "\titers: 5100, epoch: 26 | loss for each model: [0.6697867450475072]\n",
      "\tspeed: 0.0223s/iter\n",
      "\titers: 5200, epoch: 26 | loss for each model: [0.6655276213504839]\n",
      "\tspeed: 0.0202s/iter\n",
      "\titers: 5300, epoch: 26 | loss for each model: [0.6589691191062085]\n",
      "\tspeed: 0.0205s/iter\n",
      "\titers: 5400, epoch: 26 | loss for each model: [0.6541097427459641]\n",
      "\tspeed: 0.0226s/iter\n",
      "\titers: 5500, epoch: 26 | loss for each model: [0.6500150385348719]\n",
      "\tspeed: 0.0198s/iter\n",
      "\titers: 5600, epoch: 26 | loss for each model: [0.6464085506901028]\n",
      "\tspeed: 0.0202s/iter\n",
      "\titers: 5700, epoch: 26 | loss for each model: [0.6447629346694029]\n",
      "\tspeed: 0.0212s/iter\n",
      "\titers: 5800, epoch: 26 | loss for each model: [0.640204061154509]\n",
      "\tspeed: 0.0213s/iter\n",
      "\titers: 5900, epoch: 26 | loss for each model: [0.6356871039647277]\n",
      "\tspeed: 0.0209s/iter\n",
      "\titers: 6000, epoch: 26 | loss for each model: [0.6324505826406336]\n",
      "\tspeed: 0.0228s/iter\n",
      "Epoch: 26 cost time: 125.0348174571991\n",
      "Epoch: 26, Train Loss: [0.6324505826406336], Vali Loss: [0.5538220380214934], Test Loss: [0.5455354452133179]\n",
      "ðŸ” Phase changed from pilot â†’ ising\n",
      "Saving model 0 during 'ising' phase regardless of loss.\n",
      "Model 0: Validation loss decreased (0.366435 --> 0.553822).  Saving model ...\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Current phase set to: ising\n",
      "\titers: 100, epoch: 27 | loss for each model: [0.37352459446527064]\n",
      "\tspeed: 0.0199s/iter\n",
      "\titers: 200, epoch: 27 | loss for each model: [0.3998635566525627]\n",
      "\tspeed: 0.0201s/iter\n",
      "\titers: 300, epoch: 27 | loss for each model: [0.3696964519626151]\n",
      "\tspeed: 0.0230s/iter\n",
      "\titers: 400, epoch: 27 | loss for each model: [0.36020680408924816]\n",
      "\tspeed: 0.0244s/iter\n",
      "\titers: 500, epoch: 27 | loss for each model: [0.3689403777960688]\n",
      "\tspeed: 0.0281s/iter\n",
      "\titers: 600, epoch: 27 | loss for each model: [0.38173048924305475]\n",
      "\tspeed: 0.0228s/iter\n",
      "\titers: 700, epoch: 27 | loss for each model: [0.3701948124444711]\n",
      "\tspeed: 0.0198s/iter\n",
      "\titers: 800, epoch: 27 | loss for each model: [0.363851394730882]\n",
      "\tspeed: 0.0201s/iter\n",
      "\titers: 900, epoch: 27 | loss for each model: [0.3689688172927385]\n",
      "\tspeed: 0.0186s/iter\n",
      "\titers: 1000, epoch: 27 | loss for each model: [0.36126499134732876]\n",
      "\tspeed: 0.0210s/iter\n",
      "\titers: 1100, epoch: 27 | loss for each model: [0.3656977058227428]\n",
      "\tspeed: 0.0209s/iter\n",
      "\titers: 1200, epoch: 27 | loss for each model: [0.3684592204267392]\n",
      "\tspeed: 0.0199s/iter\n",
      "\titers: 1300, epoch: 27 | loss for each model: [0.3670903402548104]\n",
      "\tspeed: 0.0200s/iter\n",
      "\titers: 1400, epoch: 27 | loss for each model: [0.36909910467943907]\n",
      "\tspeed: 0.0220s/iter\n",
      "\titers: 1500, epoch: 27 | loss for each model: [0.36305936355151547]\n",
      "\tspeed: 0.0196s/iter\n",
      "\titers: 1600, epoch: 27 | loss for each model: [0.35697835610662876]\n",
      "\tspeed: 0.0194s/iter\n",
      "\titers: 1700, epoch: 27 | loss for each model: [0.35446454363046487]\n",
      "\tspeed: 0.0208s/iter\n",
      "\titers: 1800, epoch: 27 | loss for each model: [0.3529124036497928]\n",
      "\tspeed: 0.0224s/iter\n",
      "\titers: 1900, epoch: 27 | loss for each model: [0.3479621243684577]\n",
      "\tspeed: 0.0192s/iter\n",
      "\titers: 2000, epoch: 27 | loss for each model: [0.3484362194862915]\n",
      "\tspeed: 0.0200s/iter\n",
      "\titers: 2100, epoch: 27 | loss for each model: [0.3503544623177731]\n",
      "\tspeed: 0.0243s/iter\n",
      "\titers: 2200, epoch: 27 | loss for each model: [0.34821435845200377]\n",
      "\tspeed: 0.0207s/iter\n",
      "\titers: 2300, epoch: 27 | loss for each model: [0.3452389922498918]\n",
      "\tspeed: 0.0191s/iter\n",
      "\titers: 2400, epoch: 27 | loss for each model: [0.34766049170864183]\n",
      "\tspeed: 0.0198s/iter\n",
      "\titers: 2500, epoch: 27 | loss for each model: [0.3437138693951303]\n",
      "\tspeed: 0.0207s/iter\n",
      "\titers: 2600, epoch: 27 | loss for each model: [0.34264871869193697]\n",
      "\tspeed: 0.0191s/iter\n",
      "\titers: 2700, epoch: 27 | loss for each model: [0.33655550385275596]\n",
      "\tspeed: 0.0193s/iter\n",
      "\titers: 2800, epoch: 27 | loss for each model: [0.3402340337374439]\n",
      "\tspeed: 0.0197s/iter\n",
      "\titers: 2900, epoch: 27 | loss for each model: [0.34553581370299696]\n",
      "\tspeed: 0.0233s/iter\n",
      "\titers: 3000, epoch: 27 | loss for each model: [0.34255026400300753]\n",
      "\tspeed: 0.0213s/iter\n",
      "\titers: 3100, epoch: 27 | loss for each model: [0.3387576409983036]\n",
      "\tspeed: 0.0203s/iter\n",
      "\titers: 3200, epoch: 27 | loss for each model: [0.3390044424953703]\n",
      "\tspeed: 0.0223s/iter\n",
      "\titers: 3300, epoch: 27 | loss for each model: [0.33554578299819365]\n",
      "\tspeed: 0.0207s/iter\n",
      "\titers: 3400, epoch: 27 | loss for each model: [0.33397991379536346]\n",
      "\tspeed: 0.0216s/iter\n",
      "\titers: 3500, epoch: 27 | loss for each model: [0.33532001392958255]\n",
      "\tspeed: 0.0202s/iter\n",
      "\titers: 3600, epoch: 27 | loss for each model: [0.3316004392263373]\n",
      "\tspeed: 0.0209s/iter\n",
      "\titers: 3700, epoch: 27 | loss for each model: [0.3289889523605234]\n",
      "\tspeed: 0.0201s/iter\n",
      "\titers: 3800, epoch: 27 | loss for each model: [0.32788243288158186]\n",
      "\tspeed: 0.0209s/iter\n",
      "\titers: 3900, epoch: 27 | loss for each model: [0.3276377834653921]\n",
      "\tspeed: 0.0211s/iter\n",
      "\titers: 4000, epoch: 27 | loss for each model: [0.32817871405122423]\n",
      "\tspeed: 0.0212s/iter\n",
      "\titers: 4100, epoch: 27 | loss for each model: [0.3269606969340367]\n",
      "\tspeed: 0.0213s/iter\n",
      "\titers: 4200, epoch: 27 | loss for each model: [0.32828761027832765]\n",
      "\tspeed: 0.0201s/iter\n",
      "\titers: 4300, epoch: 27 | loss for each model: [0.3303774900440476]\n",
      "\tspeed: 0.0217s/iter\n",
      "\titers: 4400, epoch: 27 | loss for each model: [0.32965860874923236]\n",
      "\tspeed: 0.0194s/iter\n",
      "\titers: 4500, epoch: 27 | loss for each model: [0.32762884430216704]\n",
      "\tspeed: 0.0194s/iter\n",
      "\titers: 4600, epoch: 27 | loss for each model: [0.32684643070730407]\n",
      "\tspeed: 0.0198s/iter\n",
      "\titers: 4700, epoch: 27 | loss for each model: [0.3233424673660502]\n",
      "\tspeed: 0.0225s/iter\n",
      "\titers: 4800, epoch: 27 | loss for each model: [0.32115969358085444]\n",
      "\tspeed: 0.0222s/iter\n",
      "\titers: 4900, epoch: 27 | loss for each model: [0.3203801957429185]\n",
      "\tspeed: 0.0213s/iter\n",
      "\titers: 5000, epoch: 27 | loss for each model: [0.31977124036447496]\n",
      "\tspeed: 0.0224s/iter\n",
      "\titers: 5100, epoch: 27 | loss for each model: [0.3188790945874415]\n",
      "\tspeed: 0.0207s/iter\n",
      "\titers: 5200, epoch: 27 | loss for each model: [0.31664723488141205]\n",
      "\tspeed: 0.0208s/iter\n",
      "\titers: 5300, epoch: 27 | loss for each model: [0.3158799612055091]\n",
      "\tspeed: 0.0197s/iter\n",
      "\titers: 5400, epoch: 27 | loss for each model: [0.316076484492358]\n",
      "\tspeed: 0.0213s/iter\n",
      "\titers: 5500, epoch: 27 | loss for each model: [0.3150865928804745]\n",
      "\tspeed: 0.0198s/iter\n",
      "\titers: 5600, epoch: 27 | loss for each model: [0.3165479307262649]\n",
      "\tspeed: 0.0234s/iter\n",
      "\titers: 5700, epoch: 27 | loss for each model: [0.3154850200724659]\n",
      "\tspeed: 0.0194s/iter\n",
      "\titers: 5800, epoch: 27 | loss for each model: [0.3151138326248098]\n",
      "\tspeed: 0.0217s/iter\n",
      "\titers: 5900, epoch: 27 | loss for each model: [0.31606987991569546]\n",
      "\tspeed: 0.0200s/iter\n",
      "\titers: 6000, epoch: 27 | loss for each model: [0.3144347302192085]\n",
      "\tspeed: 0.0202s/iter\n",
      "Epoch: 27 cost time: 125.5713140964508\n",
      "Epoch: 27, Train Loss: [0.3144347302192085], Vali Loss: [0.49370498099225635], Test Loss: [0.4868865857521693]\n",
      "Saving model 0 during 'ising' phase regardless of loss.\n",
      "Model 0: Validation loss decreased (0.553822 --> 0.493705).  Saving model ...\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Current phase set to: ising\n",
      "\titers: 100, epoch: 28 | loss for each model: [0.2489665380376391]\n",
      "\tspeed: 0.0204s/iter\n",
      "\titers: 200, epoch: 28 | loss for each model: [0.24825621252064592]\n",
      "\tspeed: 0.0185s/iter\n",
      "\titers: 300, epoch: 28 | loss for each model: [0.2759974968678822]\n",
      "\tspeed: 0.0177s/iter\n",
      "\titers: 400, epoch: 28 | loss for each model: [0.26442752328217467]\n",
      "\tspeed: 0.0182s/iter\n",
      "\titers: 500, epoch: 28 | loss for each model: [0.29274329163585205]\n",
      "\tspeed: 0.0195s/iter\n",
      "\titers: 600, epoch: 28 | loss for each model: [0.28829425876113723]\n",
      "\tspeed: 0.0189s/iter\n",
      "\titers: 700, epoch: 28 | loss for each model: [0.2724241024961105]\n",
      "\tspeed: 0.0200s/iter\n",
      "\titers: 800, epoch: 28 | loss for each model: [0.2576779502572572]\n",
      "\tspeed: 0.0210s/iter\n",
      "\titers: 900, epoch: 28 | loss for each model: [0.2525725501275641]\n",
      "\tspeed: 0.0180s/iter\n",
      "\titers: 1000, epoch: 28 | loss for each model: [0.25654486917697067]\n",
      "\tspeed: 0.0196s/iter\n",
      "\titers: 1100, epoch: 28 | loss for each model: [0.26109132319586936]\n",
      "\tspeed: 0.0182s/iter\n",
      "\titers: 1200, epoch: 28 | loss for each model: [0.26714131578379846]\n",
      "\tspeed: 0.0178s/iter\n",
      "\titers: 1300, epoch: 28 | loss for each model: [0.2715336336207894]\n",
      "\tspeed: 0.0192s/iter\n",
      "\titers: 1400, epoch: 28 | loss for each model: [0.2759140132781197]\n",
      "\tspeed: 0.0201s/iter\n",
      "\titers: 1500, epoch: 28 | loss for each model: [0.2766008815514991]\n",
      "\tspeed: 0.0203s/iter\n",
      "\titers: 1600, epoch: 28 | loss for each model: [0.2771155814685244]\n",
      "\tspeed: 0.0202s/iter\n",
      "\titers: 1700, epoch: 28 | loss for each model: [0.2767083837581466]\n",
      "\tspeed: 0.0196s/iter\n",
      "\titers: 1800, epoch: 28 | loss for each model: [0.2737959454160025]\n",
      "\tspeed: 0.0174s/iter\n",
      "\titers: 1900, epoch: 28 | loss for each model: [0.27256507631635607]\n",
      "\tspeed: 0.0188s/iter\n",
      "\titers: 2000, epoch: 28 | loss for each model: [0.26839224616449064]\n",
      "\tspeed: 0.0190s/iter\n",
      "\titers: 2100, epoch: 28 | loss for each model: [0.26234285056888307]\n",
      "\tspeed: 0.0200s/iter\n",
      "\titers: 2200, epoch: 28 | loss for each model: [0.2598930093392383]\n",
      "\tspeed: 0.0202s/iter\n",
      "\titers: 2300, epoch: 28 | loss for each model: [0.26146943401215655]\n",
      "\tspeed: 0.0210s/iter\n",
      "\titers: 2400, epoch: 28 | loss for each model: [0.2570673344748381]\n",
      "\tspeed: 0.0211s/iter\n",
      "\titers: 2500, epoch: 28 | loss for each model: [0.26024107597176627]\n",
      "\tspeed: 0.0206s/iter\n",
      "\titers: 2600, epoch: 28 | loss for each model: [0.2582070451669474]\n",
      "\tspeed: 0.0212s/iter\n",
      "\titers: 2700, epoch: 28 | loss for each model: [0.2562283382131217]\n",
      "\tspeed: 0.0200s/iter\n",
      "\titers: 2800, epoch: 28 | loss for each model: [0.255919405670967]\n",
      "\tspeed: 0.0195s/iter\n",
      "\titers: 2900, epoch: 28 | loss for each model: [0.25519930385272693]\n",
      "\tspeed: 0.0188s/iter\n",
      "\titers: 3000, epoch: 28 | loss for each model: [0.2570792624213039]\n",
      "\tspeed: 0.0215s/iter\n",
      "\titers: 3100, epoch: 28 | loss for each model: [0.25528722983505436]\n",
      "\tspeed: 0.0250s/iter\n",
      "\titers: 3200, epoch: 28 | loss for each model: [0.2580729729982727]\n",
      "\tspeed: 0.0229s/iter\n",
      "\titers: 3300, epoch: 28 | loss for each model: [0.25671147807370953]\n",
      "\tspeed: 0.0222s/iter\n",
      "\titers: 3400, epoch: 28 | loss for each model: [0.2543824654442848]\n",
      "\tspeed: 0.0213s/iter\n",
      "\titers: 3500, epoch: 28 | loss for each model: [0.2560475965811233]\n",
      "\tspeed: 0.0201s/iter\n",
      "\titers: 3600, epoch: 28 | loss for each model: [0.2555336462019164]\n",
      "\tspeed: 0.0207s/iter\n",
      "\titers: 3700, epoch: 28 | loss for each model: [0.2540658169923631]\n",
      "\tspeed: 0.0207s/iter\n",
      "\titers: 3800, epoch: 28 | loss for each model: [0.25564098822772535]\n",
      "\tspeed: 0.0221s/iter\n",
      "\titers: 3900, epoch: 28 | loss for each model: [0.255511570103954]\n",
      "\tspeed: 0.0223s/iter\n",
      "\titers: 4000, epoch: 28 | loss for each model: [0.2535958669565598]\n",
      "\tspeed: 0.0215s/iter\n",
      "\titers: 4100, epoch: 28 | loss for each model: [0.2524125672129443]\n",
      "\tspeed: 0.0220s/iter\n",
      "\titers: 4200, epoch: 28 | loss for each model: [0.24981120609159396]\n",
      "\tspeed: 0.0205s/iter\n",
      "\titers: 4300, epoch: 28 | loss for each model: [0.24899198237273976]\n",
      "\tspeed: 0.0196s/iter\n",
      "\titers: 4400, epoch: 28 | loss for each model: [0.2470134545151888]\n",
      "\tspeed: 0.0195s/iter\n",
      "\titers: 4500, epoch: 28 | loss for each model: [0.24713931983080126]\n",
      "\tspeed: 0.0187s/iter\n",
      "\titers: 4600, epoch: 28 | loss for each model: [0.24626929094237746]\n",
      "\tspeed: 0.0202s/iter\n",
      "\titers: 4700, epoch: 28 | loss for each model: [0.248299164861634]\n",
      "\tspeed: 0.0205s/iter\n",
      "\titers: 4800, epoch: 28 | loss for each model: [0.24795687952862636]\n",
      "\tspeed: 0.0215s/iter\n",
      "\titers: 4900, epoch: 28 | loss for each model: [0.24873918482298235]\n",
      "\tspeed: 0.0200s/iter\n",
      "\titers: 5000, epoch: 28 | loss for each model: [0.24629491837102177]\n",
      "\tspeed: 0.0200s/iter\n",
      "\titers: 5100, epoch: 28 | loss for each model: [0.2453788125607824]\n",
      "\tspeed: 0.0186s/iter\n",
      "\titers: 5200, epoch: 28 | loss for each model: [0.24620166002568392]\n",
      "\tspeed: 0.0181s/iter\n",
      "\titers: 5300, epoch: 28 | loss for each model: [0.2458939622880122]\n",
      "\tspeed: 0.0195s/iter\n",
      "\titers: 5400, epoch: 28 | loss for each model: [0.24640833803585876]\n",
      "\tspeed: 0.0186s/iter\n",
      "\titers: 5500, epoch: 28 | loss for each model: [0.2471421965684931]\n",
      "\tspeed: 0.0215s/iter\n",
      "\titers: 5600, epoch: 28 | loss for each model: [0.24623725130888163]\n",
      "\tspeed: 0.0220s/iter\n",
      "\titers: 5700, epoch: 28 | loss for each model: [0.24557196429199904]\n",
      "\tspeed: 0.0216s/iter\n",
      "\titers: 5800, epoch: 28 | loss for each model: [0.24434786607256495]\n",
      "\tspeed: 0.0208s/iter\n",
      "\titers: 5900, epoch: 28 | loss for each model: [0.24333434152034095]\n",
      "\tspeed: 0.0205s/iter\n",
      "\titers: 6000, epoch: 28 | loss for each model: [0.2446485235214738]\n",
      "\tspeed: 0.0192s/iter\n",
      "Epoch: 28 cost time: 120.80741357803345\n",
      "Epoch: 28, Train Loss: [0.2446485235214738], Vali Loss: [0.6001379730853629], Test Loss: [0.6041090389092764]\n",
      "Saving model 0 during 'ising' phase regardless of loss.\n",
      "Model 0: Validation loss decreased (0.493705 --> 0.600138).  Saving model ...\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Current phase set to: ising\n",
      "\titers: 100, epoch: 29 | loss for each model: [0.20348335594928357]\n",
      "\tspeed: 0.0209s/iter\n",
      "\titers: 200, epoch: 29 | loss for each model: [0.19122315083583089]\n",
      "\tspeed: 0.0186s/iter\n",
      "\titers: 300, epoch: 29 | loss for each model: [0.23281501000419666]\n",
      "\tspeed: 0.0203s/iter\n",
      "\titers: 400, epoch: 29 | loss for each model: [0.24323963382355943]\n",
      "\tspeed: 0.0190s/iter\n",
      "\titers: 500, epoch: 29 | loss for each model: [0.22316680736308625]\n",
      "\tspeed: 0.0176s/iter\n",
      "\titers: 600, epoch: 29 | loss for each model: [0.21217054595295243]\n",
      "\tspeed: 0.0182s/iter\n",
      "\titers: 700, epoch: 29 | loss for each model: [0.21503677854711506]\n",
      "\tspeed: 0.0179s/iter\n",
      "\titers: 800, epoch: 29 | loss for each model: [0.2177684951930314]\n",
      "\tspeed: 0.0198s/iter\n",
      "\titers: 900, epoch: 29 | loss for each model: [0.21390499532808058]\n",
      "\tspeed: 0.0195s/iter\n",
      "\titers: 1000, epoch: 29 | loss for each model: [0.22166158229103894]\n",
      "\tspeed: 0.0201s/iter\n",
      "\titers: 1100, epoch: 29 | loss for each model: [0.22336006111341042]\n",
      "\tspeed: 0.0188s/iter\n",
      "\titers: 1200, epoch: 29 | loss for each model: [0.22076403092252198]\n",
      "\tspeed: 0.0195s/iter\n",
      "\titers: 1300, epoch: 29 | loss for each model: [0.21921060208156212]\n",
      "\tspeed: 0.0179s/iter\n",
      "\titers: 1400, epoch: 29 | loss for each model: [0.21909767970565425]\n",
      "\tspeed: 0.0185s/iter\n",
      "\titers: 1500, epoch: 29 | loss for each model: [0.22281214121942564]\n",
      "\tspeed: 0.0189s/iter\n",
      "\titers: 1600, epoch: 29 | loss for each model: [0.22080849332152866]\n",
      "\tspeed: 0.0215s/iter\n",
      "\titers: 1700, epoch: 29 | loss for each model: [0.2199021826903353]\n",
      "\tspeed: 0.0188s/iter\n",
      "\titers: 1800, epoch: 29 | loss for each model: [0.218175579084693]\n",
      "\tspeed: 0.0192s/iter\n",
      "\titers: 1900, epoch: 29 | loss for each model: [0.2166068305401591]\n",
      "\tspeed: 0.0191s/iter\n",
      "\titers: 2000, epoch: 29 | loss for each model: [0.21118242549966817]\n",
      "\tspeed: 0.0187s/iter\n",
      "\titers: 2100, epoch: 29 | loss for each model: [0.2152432386514071]\n",
      "\tspeed: 0.0208s/iter\n",
      "\titers: 2200, epoch: 29 | loss for each model: [0.21686812031057673]\n",
      "\tspeed: 0.0184s/iter\n",
      "\titers: 2300, epoch: 29 | loss for each model: [0.2170174057684325]\n",
      "\tspeed: 0.0193s/iter\n",
      "\titers: 2400, epoch: 29 | loss for each model: [0.2157625149020108]\n",
      "\tspeed: 0.0187s/iter\n",
      "\titers: 2500, epoch: 29 | loss for each model: [0.2127865352198045]\n",
      "\tspeed: 0.0206s/iter\n",
      "\titers: 2600, epoch: 29 | loss for each model: [0.21484434642591974]\n",
      "\tspeed: 0.0211s/iter\n",
      "\titers: 2700, epoch: 29 | loss for each model: [0.21720401131866715]\n",
      "\tspeed: 0.0223s/iter\n",
      "\titers: 2800, epoch: 29 | loss for each model: [0.2129346545173933]\n",
      "\tspeed: 0.0227s/iter\n",
      "\titers: 2900, epoch: 29 | loss for each model: [0.20959086711563815]\n",
      "\tspeed: 0.0231s/iter\n",
      "\titers: 3000, epoch: 29 | loss for each model: [0.21148475308795303]\n",
      "\tspeed: 0.0211s/iter\n",
      "\titers: 3100, epoch: 29 | loss for each model: [0.21188176181939497]\n",
      "\tspeed: 0.0194s/iter\n",
      "\titers: 3200, epoch: 29 | loss for each model: [0.21228464889310714]\n",
      "\tspeed: 0.0208s/iter\n",
      "\titers: 3300, epoch: 29 | loss for each model: [0.2089465856405475]\n",
      "\tspeed: 0.0215s/iter\n",
      "\titers: 3400, epoch: 29 | loss for each model: [0.2098340638893628]\n",
      "\tspeed: 0.0196s/iter\n",
      "\titers: 3500, epoch: 29 | loss for each model: [0.2067885275474977]\n",
      "\tspeed: 0.0197s/iter\n",
      "\titers: 3600, epoch: 29 | loss for each model: [0.2040872371502827]\n",
      "\tspeed: 0.0201s/iter\n",
      "\titers: 3700, epoch: 29 | loss for each model: [0.20579172993571282]\n",
      "\tspeed: 0.0215s/iter\n",
      "\titers: 3800, epoch: 29 | loss for each model: [0.20543693978997668]\n",
      "\tspeed: 0.0196s/iter\n",
      "\titers: 3900, epoch: 29 | loss for each model: [0.2044685314022629]\n",
      "\tspeed: 0.0192s/iter\n",
      "\titers: 4000, epoch: 29 | loss for each model: [0.2038744381954798]\n",
      "\tspeed: 0.0222s/iter\n",
      "\titers: 4100, epoch: 29 | loss for each model: [0.2048979498123969]\n",
      "\tspeed: 0.0191s/iter\n",
      "\titers: 4200, epoch: 29 | loss for each model: [0.20600024054205668]\n",
      "\tspeed: 0.0207s/iter\n",
      "\titers: 4300, epoch: 29 | loss for each model: [0.20378145954826535]\n",
      "\tspeed: 0.0226s/iter\n",
      "\titers: 4400, epoch: 29 | loss for each model: [0.20553246136706257]\n",
      "\tspeed: 0.0205s/iter\n",
      "\titers: 4500, epoch: 29 | loss for each model: [0.2066200251654029]\n",
      "\tspeed: 0.0235s/iter\n",
      "\titers: 4600, epoch: 29 | loss for each model: [0.20863256828095908]\n",
      "\tspeed: 0.0208s/iter\n",
      "\titers: 4700, epoch: 29 | loss for each model: [0.20657538163594547]\n",
      "\tspeed: 0.0223s/iter\n",
      "\titers: 4800, epoch: 29 | loss for each model: [0.2052303482223696]\n",
      "\tspeed: 0.0218s/iter\n",
      "\titers: 4900, epoch: 29 | loss for each model: [0.2054680245786121]\n",
      "\tspeed: 0.0229s/iter\n",
      "\titers: 5000, epoch: 29 | loss for each model: [0.20546764108346216]\n",
      "\tspeed: 0.0219s/iter\n",
      "\titers: 5100, epoch: 29 | loss for each model: [0.2067204311239363]\n",
      "\tspeed: 0.0217s/iter\n",
      "\titers: 5200, epoch: 29 | loss for each model: [0.20497831639180591]\n",
      "\tspeed: 0.0208s/iter\n",
      "\titers: 5300, epoch: 29 | loss for each model: [0.20391475163004216]\n",
      "\tspeed: 0.0247s/iter\n",
      "\titers: 5400, epoch: 29 | loss for each model: [0.20493506478050963]\n",
      "\tspeed: 0.0203s/iter\n",
      "\titers: 5500, epoch: 29 | loss for each model: [0.20548786120402557]\n",
      "\tspeed: 0.0207s/iter\n",
      "\titers: 5600, epoch: 29 | loss for each model: [0.20370834721579448]\n",
      "\tspeed: 0.0217s/iter\n",
      "\titers: 5700, epoch: 29 | loss for each model: [0.20136264228110073]\n",
      "\tspeed: 0.0214s/iter\n",
      "\titers: 5800, epoch: 29 | loss for each model: [0.2024444989882422]\n",
      "\tspeed: 0.0228s/iter\n",
      "\titers: 5900, epoch: 29 | loss for each model: [0.20167098417451057]\n",
      "\tspeed: 0.0206s/iter\n",
      "\titers: 6000, epoch: 29 | loss for each model: [0.20113409586943787]\n",
      "\tspeed: 0.0206s/iter\n",
      "Epoch: 29 cost time: 122.63340663909912\n",
      "Epoch: 29, Train Loss: [0.20113409586943787], Vali Loss: [0.8293229810735012], Test Loss: [0.8057411213715872]\n",
      "Saving model 0 during 'ising' phase regardless of loss.\n",
      "Model 0: Validation loss decreased (0.600138 --> 0.829323).  Saving model ...\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Current phase set to: ising\n",
      "\titers: 100, epoch: 30 | loss for each model: [0.17248149246704997]\n",
      "\tspeed: 0.0182s/iter\n",
      "\titers: 200, epoch: 30 | loss for each model: [0.20083120797771245]\n",
      "\tspeed: 0.0149s/iter\n",
      "\titers: 300, epoch: 30 | loss for each model: [0.19050072789674535]\n",
      "\tspeed: 0.0151s/iter\n",
      "\titers: 400, epoch: 30 | loss for each model: [0.17298521198366074]\n",
      "\tspeed: 0.0157s/iter\n",
      "\titers: 500, epoch: 30 | loss for each model: [0.17692373097520703]\n",
      "\tspeed: 0.0159s/iter\n",
      "\titers: 600, epoch: 30 | loss for each model: [0.17194476059290006]\n",
      "\tspeed: 0.0145s/iter\n",
      "\titers: 700, epoch: 30 | loss for each model: [0.17202978415790768]\n",
      "\tspeed: 0.0146s/iter\n",
      "\titers: 800, epoch: 30 | loss for each model: [0.19235240237421578]\n",
      "\tspeed: 0.0149s/iter\n",
      "\titers: 900, epoch: 30 | loss for each model: [0.19058845614838044]\n",
      "\tspeed: 0.0145s/iter\n",
      "\titers: 1000, epoch: 30 | loss for each model: [0.19005245646234697]\n",
      "\tspeed: 0.0143s/iter\n",
      "\titers: 1100, epoch: 30 | loss for each model: [0.18964931388627893]\n",
      "\tspeed: 0.0146s/iter\n",
      "\titers: 1200, epoch: 30 | loss for each model: [0.18687991941143575]\n",
      "\tspeed: 0.0141s/iter\n",
      "\titers: 1300, epoch: 30 | loss for each model: [0.1837894992862623]\n",
      "\tspeed: 0.0144s/iter\n",
      "\titers: 1400, epoch: 30 | loss for each model: [0.18562264650398413]\n",
      "\tspeed: 0.0146s/iter\n",
      "\titers: 1500, epoch: 30 | loss for each model: [0.18205463273637876]\n",
      "\tspeed: 0.0153s/iter\n",
      "\titers: 1600, epoch: 30 | loss for each model: [0.18666968390799327]\n",
      "\tspeed: 0.0159s/iter\n",
      "\titers: 1700, epoch: 30 | loss for each model: [0.18436909682467426]\n",
      "\tspeed: 0.0155s/iter\n",
      "\titers: 1800, epoch: 30 | loss for each model: [0.18733893003882587]\n",
      "\tspeed: 0.0155s/iter\n",
      "\titers: 1900, epoch: 30 | loss for each model: [0.18621702249462438]\n",
      "\tspeed: 0.0147s/iter\n",
      "\titers: 2000, epoch: 30 | loss for each model: [0.1842038107876426]\n",
      "\tspeed: 0.0148s/iter\n",
      "\titers: 2100, epoch: 30 | loss for each model: [0.18170353508020765]\n",
      "\tspeed: 0.0153s/iter\n",
      "\titers: 2200, epoch: 30 | loss for each model: [0.18003621559465025]\n",
      "\tspeed: 0.0215s/iter\n",
      "\titers: 2300, epoch: 30 | loss for each model: [0.18101382864545465]\n",
      "\tspeed: 0.0289s/iter\n",
      "\titers: 2400, epoch: 30 | loss for each model: [0.1803039546409667]\n",
      "\tspeed: 0.0258s/iter\n",
      "\titers: 2500, epoch: 30 | loss for each model: [0.17961097892771885]\n",
      "\tspeed: 0.0194s/iter\n",
      "\titers: 2600, epoch: 30 | loss for each model: [0.17879913994802668]\n",
      "\tspeed: 0.0240s/iter\n",
      "\titers: 2700, epoch: 30 | loss for each model: [0.1750725593981276]\n",
      "\tspeed: 0.0251s/iter\n",
      "\titers: 2800, epoch: 30 | loss for each model: [0.18078641573563328]\n",
      "\tspeed: 0.0220s/iter\n",
      "\titers: 2900, epoch: 30 | loss for each model: [0.1825079402219256]\n",
      "\tspeed: 0.0189s/iter\n",
      "\titers: 3000, epoch: 30 | loss for each model: [0.18135176495976868]\n",
      "\tspeed: 0.0228s/iter\n",
      "\titers: 3100, epoch: 30 | loss for each model: [0.1784794399854756]\n",
      "\tspeed: 0.0224s/iter\n",
      "\titers: 3200, epoch: 30 | loss for each model: [0.17571774673445006]\n",
      "\tspeed: 0.0210s/iter\n",
      "\titers: 3300, epoch: 30 | loss for each model: [0.17631206766527488]\n",
      "\tspeed: 0.0215s/iter\n",
      "\titers: 3400, epoch: 30 | loss for each model: [0.17562678683619184]\n",
      "\tspeed: 0.0230s/iter\n",
      "\titers: 3500, epoch: 30 | loss for each model: [0.17537832237551043]\n",
      "\tspeed: 0.0193s/iter\n",
      "\titers: 3600, epoch: 30 | loss for each model: [0.17560757612260217]\n",
      "\tspeed: 0.0206s/iter\n",
      "\titers: 3700, epoch: 30 | loss for each model: [0.17378717581022776]\n",
      "\tspeed: 0.0186s/iter\n",
      "\titers: 3800, epoch: 30 | loss for each model: [0.1724770769464312]\n",
      "\tspeed: 0.0201s/iter\n",
      "\titers: 3900, epoch: 30 | loss for each model: [0.1722466627296745]\n",
      "\tspeed: 0.0296s/iter\n",
      "\titers: 4000, epoch: 30 | loss for each model: [0.1721505796670507]\n",
      "\tspeed: 0.0227s/iter\n",
      "\titers: 4100, epoch: 30 | loss for each model: [0.17122407665675837]\n",
      "\tspeed: 0.0262s/iter\n",
      "\titers: 4200, epoch: 30 | loss for each model: [0.1723694416659935]\n",
      "\tspeed: 0.0254s/iter\n",
      "\titers: 4300, epoch: 30 | loss for each model: [0.1719872787030808]\n",
      "\tspeed: 0.0225s/iter\n",
      "\titers: 4400, epoch: 30 | loss for each model: [0.17078156045918655]\n",
      "\tspeed: 0.0197s/iter\n",
      "\titers: 4500, epoch: 30 | loss for each model: [0.1703241818086989]\n",
      "\tspeed: 0.0252s/iter\n",
      "\titers: 4600, epoch: 30 | loss for each model: [0.17051265722617973]\n",
      "\tspeed: 0.0232s/iter\n",
      "\titers: 4700, epoch: 30 | loss for each model: [0.17174349076061432]\n",
      "\tspeed: 0.0198s/iter\n",
      "\titers: 4800, epoch: 30 | loss for each model: [0.16985508953016445]\n",
      "\tspeed: 0.0210s/iter\n",
      "\titers: 4900, epoch: 30 | loss for each model: [0.16851712389265988]\n",
      "\tspeed: 0.0224s/iter\n",
      "\titers: 5000, epoch: 30 | loss for each model: [0.16779191331121887]\n",
      "\tspeed: 0.0218s/iter\n",
      "\titers: 5100, epoch: 30 | loss for each model: [0.16830164020760677]\n",
      "\tspeed: 0.0203s/iter\n",
      "\titers: 5200, epoch: 30 | loss for each model: [0.16733584924118178]\n",
      "\tspeed: 0.0227s/iter\n",
      "\titers: 5300, epoch: 30 | loss for each model: [0.16639993797789804]\n",
      "\tspeed: 0.0200s/iter\n",
      "\titers: 5400, epoch: 30 | loss for each model: [0.1670571408795169]\n",
      "\tspeed: 0.0198s/iter\n",
      "\titers: 5500, epoch: 30 | loss for each model: [0.16713219737331708]\n",
      "\tspeed: 0.0192s/iter\n",
      "\titers: 5600, epoch: 30 | loss for each model: [0.16775784663183388]\n",
      "\tspeed: 0.0240s/iter\n",
      "\titers: 5700, epoch: 30 | loss for each model: [0.1662846234683303]\n",
      "\tspeed: 0.0205s/iter\n",
      "\titers: 5800, epoch: 30 | loss for each model: [0.1660041637145915]\n",
      "\tspeed: 0.0218s/iter\n",
      "\titers: 5900, epoch: 30 | loss for each model: [0.1664569940235409]\n",
      "\tspeed: 0.0201s/iter\n",
      "\titers: 6000, epoch: 30 | loss for each model: [0.16559132318908507]\n",
      "\tspeed: 0.0209s/iter\n",
      "Epoch: 30 cost time: 118.08063960075378\n",
      "Epoch: 30, Train Loss: [0.16559132318908507], Vali Loss: [0.41453256378782555], Test Loss: [0.398274098833402]\n",
      "Saving model 0 during 'ising' phase regardless of loss.\n",
      "Model 0: Validation loss decreased (0.829323 --> 0.414533).  Saving model ...\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "Ising hard-threshold dropped params: 42496 (54.97% of 77312)\n",
      "Total model parameters: 189908\n",
      "\titers: 100, epoch: 31 | loss for each model: [0.22720313850790264]\n",
      "\tspeed: 0.0156s/iter\n",
      "\titers: 200, epoch: 31 | loss for each model: [0.224857087880373]\n",
      "\tspeed: 0.0156s/iter\n",
      "\titers: 300, epoch: 31 | loss for each model: [0.22149773892015218]\n",
      "\tspeed: 0.0147s/iter\n",
      "Epoch: 31 cost time: 4.593096494674683\n",
      "Epoch: 31, Train Loss: [0.22149773892015218], Vali Loss: [0.36570344897026713], Test Loss: [0.3594951083262761]\n",
      "ðŸ” Phase changed from ising â†’ fine-tuning\n",
      "ðŸ”„ Resetting early stopping history for fine-tuning phase...\n",
      "Model 0: Validation loss decreased (inf --> 0.365703).  Saving model ...\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 32 | loss for each model: [0.2173127329722047]\n",
      "\tspeed: 0.0157s/iter\n",
      "\titers: 200, epoch: 32 | loss for each model: [0.21619697120040654]\n",
      "\tspeed: 0.0152s/iter\n",
      "\titers: 300, epoch: 32 | loss for each model: [0.21201284928868214]\n",
      "\tspeed: 0.0145s/iter\n",
      "Epoch: 32 cost time: 4.538451194763184\n",
      "Epoch: 32, Train Loss: [0.21201284928868214], Vali Loss: [0.35939920899715827], Test Loss: [0.3597193857034047]\n",
      "Model 0: Validation loss decreased (0.365703 --> 0.359399).  Saving model ...\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 33 | loss for each model: [0.19549377895891668]\n",
      "\tspeed: 0.0149s/iter\n",
      "\titers: 200, epoch: 33 | loss for each model: [0.20607621736824513]\n",
      "\tspeed: 0.0148s/iter\n",
      "\titers: 300, epoch: 33 | loss for each model: [0.2015061903372407]\n",
      "\tspeed: 0.0150s/iter\n",
      "Epoch: 33 cost time: 4.469016075134277\n",
      "Epoch: 33, Train Loss: [0.2015061903372407], Vali Loss: [0.3546439802393], Test Loss: [0.3529816468556722]\n",
      "Model 0: Validation loss decreased (0.359399 --> 0.354644).  Saving model ...\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 34 | loss for each model: [0.20591402407735587]\n",
      "\tspeed: 0.0139s/iter\n",
      "\titers: 200, epoch: 34 | loss for each model: [0.19938909919932485]\n",
      "\tspeed: 0.0143s/iter\n",
      "\titers: 300, epoch: 34 | loss for each model: [0.19178146025786796]\n",
      "\tspeed: 0.0154s/iter\n",
      "Epoch: 34 cost time: 4.359578847885132\n",
      "Epoch: 34, Train Loss: [0.19178146025786796], Vali Loss: [0.35288638320375], Test Loss: [0.3491685589154561]\n",
      "Model 0: Validation loss decreased (0.354644 --> 0.352886).  Saving model ...\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 35 | loss for each model: [0.18281064603477717]\n",
      "\tspeed: 0.0200s/iter\n",
      "\titers: 200, epoch: 35 | loss for each model: [0.186940782465972]\n",
      "\tspeed: 0.0228s/iter\n",
      "\titers: 300, epoch: 35 | loss for each model: [0.18157992825843394]\n",
      "\tspeed: 0.0219s/iter\n",
      "Epoch: 35 cost time: 6.468731880187988\n",
      "Epoch: 35, Train Loss: [0.18157992825843394], Vali Loss: [0.34988776039569935], Test Loss: [0.3464069217443466]\n",
      "Model 0: Validation loss decreased (0.352886 --> 0.349888).  Saving model ...\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 36 | loss for each model: [0.18654156524688006]\n",
      "\tspeed: 0.0227s/iter\n",
      "\titers: 200, epoch: 36 | loss for each model: [0.1751907693222165]\n",
      "\tspeed: 0.0247s/iter\n",
      "\titers: 300, epoch: 36 | loss for each model: [0.17359456250444055]\n",
      "\tspeed: 0.0222s/iter\n",
      "Epoch: 36 cost time: 6.9557671546936035\n",
      "Epoch: 36, Train Loss: [0.17359456250444055], Vali Loss: [0.3464009787173981], Test Loss: [0.3403187741835912]\n",
      "Model 0: Validation loss decreased (0.349888 --> 0.346401).  Saving model ...\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 37 | loss for each model: [0.1679962586145848]\n",
      "\tspeed: 0.0259s/iter\n",
      "\titers: 200, epoch: 37 | loss for each model: [0.1673568456200883]\n",
      "\tspeed: 0.0244s/iter\n",
      "\titers: 300, epoch: 37 | loss for each model: [0.16529866230674087]\n",
      "\tspeed: 0.0250s/iter\n",
      "Epoch: 37 cost time: 7.529110670089722\n",
      "Epoch: 37, Train Loss: [0.16529866230674087], Vali Loss: [0.34406632058163905], Test Loss: [0.34102362891038257]\n",
      "Model 0: Validation loss decreased (0.346401 --> 0.344066).  Saving model ...\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 38 | loss for each model: [0.15236126942560077]\n",
      "\tspeed: 0.0185s/iter\n",
      "\titers: 200, epoch: 38 | loss for each model: [0.15970396175049245]\n",
      "\tspeed: 0.0170s/iter\n",
      "\titers: 300, epoch: 38 | loss for each model: [0.15888194368531305]\n",
      "\tspeed: 0.0176s/iter\n",
      "Epoch: 38 cost time: 5.311447858810425\n",
      "Epoch: 38, Train Loss: [0.15888194368531305], Vali Loss: [0.3449518217685375], Test Loss: [0.3393306185801824]\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 39 | loss for each model: [0.16738546177744865]\n",
      "\tspeed: 0.0181s/iter\n",
      "\titers: 200, epoch: 39 | loss for each model: [0.15332369456999004]\n",
      "\tspeed: 0.0190s/iter\n",
      "\titers: 300, epoch: 39 | loss for each model: [0.1499240296209852]\n",
      "\tspeed: 0.0192s/iter\n",
      "Epoch: 39 cost time: 5.624554395675659\n",
      "Epoch: 39, Train Loss: [0.1499240296209852], Vali Loss: [0.3426629970682428], Test Loss: [0.3369639168183009]\n",
      "Model 0: Validation loss decreased (0.344066 --> 0.342663).  Saving model ...\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 40 | loss for each model: [0.1471643889695406]\n",
      "\tspeed: 0.0191s/iter\n",
      "\titers: 200, epoch: 40 | loss for each model: [0.14169847366400062]\n",
      "\tspeed: 0.0216s/iter\n",
      "\titers: 300, epoch: 40 | loss for each model: [0.140752164227888]\n",
      "\tspeed: 0.0211s/iter\n",
      "Epoch: 40 cost time: 6.178189277648926\n",
      "Epoch: 40, Train Loss: [0.140752164227888], Vali Loss: [0.341928501712515], Test Loss: [0.3371480455001195]\n",
      "Model 0: Validation loss decreased (0.342663 --> 0.341929).  Saving model ...\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 41 | loss for each model: [0.1373175465501845]\n",
      "\tspeed: 0.0265s/iter\n",
      "\titers: 200, epoch: 41 | loss for each model: [0.1383190847374499]\n",
      "\tspeed: 0.0229s/iter\n",
      "\titers: 300, epoch: 41 | loss for each model: [0.1368492795402805]\n",
      "\tspeed: 0.0263s/iter\n",
      "Epoch: 41 cost time: 7.56438684463501\n",
      "Epoch: 41, Train Loss: [0.1368492795402805], Vali Loss: [0.342510960203536], Test Loss: [0.3368452986081441]\n",
      "EarlyStopping counter: 1 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 42 | loss for each model: [0.1193607939593494]\n",
      "\tspeed: 0.0223s/iter\n",
      "\titers: 200, epoch: 42 | loss for each model: [0.1280229082517326]\n",
      "\tspeed: 0.0198s/iter\n",
      "\titers: 300, epoch: 42 | loss for each model: [0.12992104051013786]\n",
      "\tspeed: 0.0194s/iter\n",
      "Epoch: 42 cost time: 6.1529786586761475\n",
      "Epoch: 42, Train Loss: [0.12992104051013786], Vali Loss: [0.3429631749366192], Test Loss: [0.33267928659915924]\n",
      "EarlyStopping counter: 2 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 43 | loss for each model: [0.11769360137172043]\n",
      "\tspeed: 0.0221s/iter\n",
      "\titers: 200, epoch: 43 | loss for each model: [0.11926154082175344]\n",
      "\tspeed: 0.0194s/iter\n",
      "\titers: 300, epoch: 43 | loss for each model: [0.12074481983358662]\n",
      "\tspeed: 0.0184s/iter\n",
      "Epoch: 43 cost time: 5.982393980026245\n",
      "Epoch: 43, Train Loss: [0.12074481983358662], Vali Loss: [0.34261164132584915], Test Loss: [0.33513931433359784]\n",
      "EarlyStopping counter: 3 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 44 | loss for each model: [0.11011265333741903]\n",
      "\tspeed: 0.0201s/iter\n",
      "\titers: 200, epoch: 44 | loss for each model: [0.11899751531891525]\n",
      "\tspeed: 0.0207s/iter\n",
      "\titers: 300, epoch: 44 | loss for each model: [0.11761986511449019]\n",
      "\tspeed: 0.0197s/iter\n",
      "Epoch: 44 cost time: 6.047416925430298\n",
      "Epoch: 44, Train Loss: [0.11761986511449019], Vali Loss: [0.3437472734045475], Test Loss: [0.34020450711250305]\n",
      "EarlyStopping counter: 4 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 45 | loss for each model: [0.1113511878438294]\n",
      "\tspeed: 0.0192s/iter\n",
      "\titers: 200, epoch: 45 | loss for each model: [0.10800649859011173]\n",
      "\tspeed: 0.0180s/iter\n",
      "\titers: 300, epoch: 45 | loss for each model: [0.10652048179879785]\n",
      "\tspeed: 0.0179s/iter\n",
      "Epoch: 45 cost time: 5.5107643604278564\n",
      "Epoch: 45, Train Loss: [0.10652048179879785], Vali Loss: [0.34375894133080825], Test Loss: [0.3424680680036545]\n",
      "EarlyStopping counter: 5 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 46 | loss for each model: [0.10214930793270469]\n",
      "\tspeed: 0.0184s/iter\n",
      "\titers: 200, epoch: 46 | loss for each model: [0.10493164408486337]\n",
      "\tspeed: 0.0220s/iter\n",
      "\titers: 300, epoch: 46 | loss for each model: [0.10251533499297996]\n",
      "\tspeed: 0.0321s/iter\n",
      "Epoch: 46 cost time: 7.2417449951171875\n",
      "Epoch: 46, Train Loss: [0.10251533499297996], Vali Loss: [0.34581426673747123], Test Loss: [0.34080319106578827]\n",
      "EarlyStopping counter: 6 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 47 | loss for each model: [0.09530464453622699]\n",
      "\tspeed: 0.0154s/iter\n",
      "\titers: 200, epoch: 47 | loss for each model: [0.09736080975271762]\n",
      "\tspeed: 0.0149s/iter\n",
      "\titers: 300, epoch: 47 | loss for each model: [0.09921043732513984]\n",
      "\tspeed: 0.0146s/iter\n",
      "Epoch: 47 cost time: 4.497549533843994\n",
      "Epoch: 47, Train Loss: [0.09921043732513984], Vali Loss: [0.3472119500028326], Test Loss: [0.34117041031519574]\n",
      "EarlyStopping counter: 7 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 48 | loss for each model: [0.08493704621680082]\n",
      "\tspeed: 0.0146s/iter\n",
      "\titers: 200, epoch: 48 | loss for each model: [0.08748359871562571]\n",
      "\tspeed: 0.0143s/iter\n",
      "\titers: 300, epoch: 48 | loss for each model: [0.09134152964688838]\n",
      "\tspeed: 0.0146s/iter\n",
      "Epoch: 48 cost time: 4.347846269607544\n",
      "Epoch: 48, Train Loss: [0.09134152964688838], Vali Loss: [0.34895340686148785], Test Loss: [0.3524864415327708]\n",
      "EarlyStopping counter: 8 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 49 | loss for each model: [0.08519870771095156]\n",
      "\tspeed: 0.0140s/iter\n",
      "\titers: 200, epoch: 49 | loss for each model: [0.09051539289765059]\n",
      "\tspeed: 0.0140s/iter\n",
      "\titers: 300, epoch: 49 | loss for each model: [0.09030760704694937]\n",
      "\tspeed: 0.0140s/iter\n",
      "Epoch: 49 cost time: 4.202934503555298\n",
      "Epoch: 49, Train Loss: [0.09030760704694937], Vali Loss: [0.3507079748397178], Test Loss: [0.347946435213089]\n",
      "EarlyStopping counter: 9 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 50 | loss for each model: [0.08829248807393014]\n",
      "\tspeed: 0.0141s/iter\n",
      "\titers: 200, epoch: 50 | loss for each model: [0.08307483659591526]\n",
      "\tspeed: 0.0139s/iter\n",
      "\titers: 300, epoch: 50 | loss for each model: [0.08401794844927887]\n",
      "\tspeed: 0.0140s/iter\n",
      "Epoch: 50 cost time: 4.1979734897613525\n",
      "Epoch: 50, Train Loss: [0.08401794844927887], Vali Loss: [0.35210371905184806], Test Loss: [0.3512139519055684]\n",
      "EarlyStopping counter: 10 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 51 | loss for each model: [0.07725442140828818]\n",
      "\tspeed: 0.0147s/iter\n",
      "\titers: 200, epoch: 51 | loss for each model: [0.0804017924866639]\n",
      "\tspeed: 0.0153s/iter\n",
      "\titers: 300, epoch: 51 | loss for each model: [0.0816551948315464]\n",
      "\tspeed: 0.0141s/iter\n",
      "Epoch: 51 cost time: 4.41556453704834\n",
      "Epoch: 51, Train Loss: [0.0816551948315464], Vali Loss: [0.35798976332583327], Test Loss: [0.355084627866745]\n",
      "EarlyStopping counter: 11 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 52 | loss for each model: [0.08498438659589738]\n",
      "\tspeed: 0.0193s/iter\n",
      "\titers: 200, epoch: 52 | loss for each model: [0.0795960864587687]\n",
      "\tspeed: 0.0193s/iter\n",
      "\titers: 300, epoch: 52 | loss for each model: [0.0788476130583634]\n",
      "\tspeed: 0.0201s/iter\n",
      "Epoch: 52 cost time: 5.8752851486206055\n",
      "Epoch: 52, Train Loss: [0.0788476130583634], Vali Loss: [0.35685692886088755], Test Loss: [0.35529208183288574]\n",
      "EarlyStopping counter: 12 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 53 | loss for each model: [0.08269665813073517]\n",
      "\tspeed: 0.0215s/iter\n",
      "\titers: 200, epoch: 53 | loss for each model: [0.07726564043667167]\n",
      "\tspeed: 0.0212s/iter\n",
      "\titers: 300, epoch: 53 | loss for each model: [0.07551507299455504]\n",
      "\tspeed: 0.0216s/iter\n",
      "Epoch: 53 cost time: 6.431620836257935\n",
      "Epoch: 53, Train Loss: [0.07551507299455504], Vali Loss: [0.36242232868011964], Test Loss: [0.3677861789862315]\n",
      "EarlyStopping counter: 13 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 54 | loss for each model: [0.07720216631423682]\n",
      "\tspeed: 0.0269s/iter\n",
      "\titers: 200, epoch: 54 | loss for each model: [0.07433380603790284]\n",
      "\tspeed: 0.0217s/iter\n",
      "\titers: 300, epoch: 54 | loss for each model: [0.07183533300335208]\n",
      "\tspeed: 0.0228s/iter\n",
      "Epoch: 54 cost time: 7.150823593139648\n",
      "Epoch: 54, Train Loss: [0.07183533300335208], Vali Loss: [0.3655249203773255], Test Loss: [0.365853692094485]\n",
      "EarlyStopping counter: 14 out of 100\n",
      "Current phase set to: fine-tuning\n",
      "\titers: 100, epoch: 55 | loss for each model: [0.06534152765059843]\n",
      "\tspeed: 0.0156s/iter\n",
      "\titers: 200, epoch: 55 | loss for each model: [0.06561766763101332]\n",
      "\tspeed: 0.0154s/iter\n",
      "\titers: 300, epoch: 55 | loss for each model: [0.06570622693824892]\n",
      "\tspeed: 0.0176s/iter\n",
      "Epoch: 55 cost time: 4.85654354095459\n",
      "Epoch: 55, Train Loss: [0.06570622693824892], Vali Loss: [0.365973395870087], Test Loss: [0.3626835544904073]\n",
      "EarlyStopping counter: 15 out of 100\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[VisionTransformerWithBBB(\n",
       "   (patch_embedding): BBBLinear(in_features=147, out_features=64, bias=True)\n",
       "   (encoder): ModuleList(\n",
       "     (0-1): 2 x TransformerEncoderLayerWithBBB(\n",
       "       (norm1): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "       (self_attn): MultiheadAttention(\n",
       "         (out_proj): NonDynamicallyQuantizableLinear(in_features=64, out_features=64, bias=True)\n",
       "       )\n",
       "       (norm2): LayerNorm((64,), eps=1e-05, elementwise_affine=True)\n",
       "       (mlp): Sequential(\n",
       "         (0): BBBLinear(in_features=64, out_features=256, bias=True)\n",
       "         (1): GELU(approximate='none')\n",
       "         (2): Dropout(p=0.0, inplace=False)\n",
       "         (3): BBBLinear(in_features=256, out_features=64, bias=True)\n",
       "         (4): Dropout(p=0.0, inplace=False)\n",
       "       )\n",
       "     )\n",
       "   )\n",
       "   (classification_head): Sequential(\n",
       "     (0): BBBLinear(in_features=64, out_features=32, bias=True)\n",
       "     (1): ReLU()\n",
       "     (2): Dropout(p=0.0, inplace=False)\n",
       "     (3): BBBLinear(in_features=32, out_features=10, bias=True)\n",
       "   )\n",
       " )]"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "f7e3897d-92ec-4a95-8a79-a91362dd6021",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model 0 - Accuracy: 89.65%\n"
     ]
    }
   ],
   "source": [
    "trainer.evaluate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "2cd70075-8fa2-4793-bc56-822b5aa51a17",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'dataset': 'mnist', 'train_samples': 6000, 'val_samples': 48000, 'test_samples': 6000, 'train_error': [0.06570622693824892], 'val_error': [0.365973395870087], 'test_error': [0.3626835544904073], 'train_acc': [97.51666666666667], 'val_acc': [89.56041666666667], 'test_acc': [89.53333333333333], 'train_err': [2.4833333333333343], 'val_err': [10.439583333333331], 'test_err': [10.466666666666669], 'num_parameters': 189908, 'ising_dropped': 42496, 'total_potential': 77312}\n"
     ]
    }
   ],
   "source": [
    "stats = trainer.get_run_stats()\n",
    "print(stats)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
